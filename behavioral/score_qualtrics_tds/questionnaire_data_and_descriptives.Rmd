---
title: "Score TDS Qualtrics Data"
author: "John Flournoy"
date: "`r Sys.Date()`"
output: 
    pdf_document:
        toc: true
        toc_depth: 4
---

This presents both a walk-through for how you could go about adding a new questionnaire to be scored, and also should provide up-to-date descriptives and scored scales every time you recompile this Rmd document.

It would be nice if this were something completely automated. Unfortunately, the nature of data that is still under collection, and the fact that there are a lot of moving pieces means that something totally automated is likely to break pretty easily (at least, something automated coded by me). So this document will take a highly modular approach so hopefully if something goes wrong, you can see more exactly where that happens. I'll try to explain every step pretty verbosely too. You should probably be reading this document in R Studio. Make sure you're up to date with upgrades.

## Setting options

If you're reading the compiled HTML, you won't see the options below, because we've writtent `warning=F,echo=F,message=F,error=F` in the head of the chunk. You can change this by replacing the "F"s with "T"s.

```{r warning=F,echo=F,message=F,error=F}
knitr::opts_chunk$set(error = T, warning = T, message = F)

#Set these options for your situation:

cred_file_location <- '~/.teenstudytoken'
pid_column_name <- 'SID'
age_var <- 'Age'
gender_var <- 'Gender'
gender_female <- 1 # value for female
gender_male <- 0 # value for male
pdss_gender_code <- c(m=gender_male, f=gender_female)
pdss_gender_mix <- 'mf' #'mf' for both M and F, 'm' for M only, 'f' for F only
exclude_SID <- c('', '999') # subject IDs to exclude
identifiableData <- '(DOB|Ethnicity|Work|Grade|School|TEXT|Addl_Probs|Reasons|Decribe|Concerns|BestThings|Describe|Started|Ended)' # exclude when printing duplicates
output_file_dir <- '/data/jflournoy/TDS/behavior/scored_qualtrics_data/'
tds2_wave1_rubric_dir <- '~/code_new/TDS_scripts/behavioral/score_qualtrics_tds/rubrics/tds2/wave1/'
```

## Install the `scorequaltrics` package

We need to have the scorequaltrics package installed. I wrote this so that I can maintain helpful functions related to scoring.

```{r eval = F}
#this chunk won't evaluate. If you need to 
#install the package, run this by hand.
devtools::install_github('jflournoy/qualtrics')
```

## Accessing qualtrics data

You also need to have a token in a YAML formatted file for accessing qualtrics via the API. It's formatted like:

```
user: username
token: apitoken
```

Once we've loaded this, we can get a list of questionnaires.

```{r}
library(scorequaltrics)

library(dplyr)
library(tidyr)

credentials <- scorequaltrics::creds_from_file(cred_file_location)

rawSurveys <- scorequaltrics::get_surveys(credentials)
rawSurveysTDS <- filter(rawSurveys, grepl('.*(TDS1|TDS2|TDS3).*',SurveyName))

knitr::kable(arrange(select(rawSurveysTDS, SurveyName), SurveyName))
```

We have a lot of different questionnaires from different samples and different sessions. For simplicity, and to aid in diagnosing any problems, we can proceed through each sample and each wave of data collection. _Note_, however, that if we ensured that naming conventions were consistent across all questionnaires and rubrics, and if we had accurate session dates attached, we could score everything in one fell swoop.

## TDS 2

This is the first sample collected, so we can begin here. I'll demonstrate in this how to do a single massive data scoring. See below for how you can get more information about scales that have been constructed in a psychometric tradition, and that therefore are easy to evaluate using standard reliability metrics.

### Wave 1

First, we download the data for the surveys we want.

```{r getsurveydata_tds2_wave1}
tds2_wave1_surveys <- rawSurveysTDS %>%
    filter(grepl('TDS2 (Session [12]|CBCL|- PDS)', SurveyName))

print(tds2_wave1_surveys$SurveyName)

tds2_wave1_long <- scorequaltrics::get_survey_data(tds2_wave1_surveys, 
                                                   credentials, 
                                                   pid_col = pid_column_name)

dim(tds2_wave1_long)
names(tds2_wave1_long)
```

The resulting data frame should have a lot of rows (the first part of the output of `dim`) and 4 columns.

```{r echo = 'asis', echo = F}
#this chunk will not display in the compiled document, but it will
#echo text that will be displayed in the final document if something
#is wrong (or right).
if(all(dim(tds2_wave1_long)[1] > 500, dim(tds2_wave1_long)[2] == 4)){
    cat(paste0('It looks like all is in order here. Note that the PID column is named "', names(tds2_wave1_long)[1], '".'))
} else {
    cat('Something is wrong though. Dang.')
}
```


Before doing any scoring, we should take care of all the complex response recoding that may be specified. So We'll load all the response recoding rubrics and apply those. It's important that you pass the full path of the file to the next function, so if you use `dir` to collect filenames as I do below, make sure you set `full.names = TRUE`.

```{r resp_recode_tds2_wave1}
dir(file.path(tds2_wave1_rubric_dir), pattern = '.*response_recoding.*.csv')
#You should see a result below -- if not, the path is likely wrong.

tds2_wave1_recoding_rubrics <- data.frame(file = dir(file.path(tds2_wave1_rubric_dir), 
                                                     pattern = '.*response_recoding.*.csv',
                                                     full.names = TRUE))

tds2_wave1_recoding_data_long <- scorequaltrics::get_rubrics(tds2_wave1_recoding_rubrics, 
                                                             type = 'recoding')

tds2_wave1_long_recoded <- scorequaltrics::recode_responses(tds2_wave1_long, 
                                                            tds2_wave1_recoding_data_long)
```

Now let's load in the scoring rubrics.

```{r rubrics_tds2_wave1}
tds2_wave1_scoring_rubrics <- data.frame(file = dir(file.path(tds2_wave1_rubric_dir), 
                                                    pattern = '.*scoring_rubric.*.csv',
                                                    full.names = TRUE))
                                         
tds2_wave1_scoring_data_long <- scorequaltrics::get_rubrics(tds2_wave1_scoring_rubrics, 
                                                            type = 'scoring')

head(tds2_wave1_scoring_data_long[, -1])
```

#### Cleaning

We can make sure we clean out duplicate responses which will help later with ensuring that scale scores are calculated from teh correct subset of items. This is a point at which, if there is something funky going on, you'll want to investigate it and make a decision. For example, if a participant has two conflicting answers to the same question for the same wave, it's likely that a small investigation should commence. 

We can also ensure that we're only scoring data for participants with the correct ID numbers. The line in the middle of the first call, `filter(grepl('[1234]\\d\\d', SID))`, ensures we only keep people with ID's starting with "1".

Before we do that, we can ensure that we're only keeping the data in the scoring rubrics in the first place.



```{r cleaning}
tds2_wave1_long_recoded_nodupes <- tds2_wave1_long_recoded %>%
    get_items_in_rubric(tds2_wave1_scoring_data_long) %>%
    filter(grepl('1\\d\\d', SID)) %>%
    scorequaltrics::clean_dupes(pid_col = 'SID')
```

If you get "NAs introduced by coercion" it probably means that one of the rubrics references a column that has text input that is not transformable into a number. For example, if the questionnaire asks for ethnicity and someone writes in "White" it is not possible to turn that into a score to be used in a scale calculation (but there's a rubric that thinks it can). We can check that by using the function `scorequaltrics::get_uncoercibles()`.

```{r textentries}
tds2_wave1_uncoer <- tds2_wave1_long_recoded %>%
    get_items_in_rubric(tds2_wave1_scoring_data_long) %>%
    filter(grepl('[1234]\\d\\d', SID)) %>%
    scorequaltrics::get_uncoercibles() %>%
    distinct(item, value)

head(tds2_wave1_uncoer, 10)

unique(tds2_wave1_uncoer$item)
```


Now we can look at what rubrics have those items, if any.

```{r}
tds2_wave1_scoring_data_long %>%
    filter(column_name %in% unique(tds2_wave1_uncoer$item),
           include %in% c(1, "1", "sum", "prod")) %>%
    ungroup() %>%
    select(scale_name, scored_scale, column_name, include)
```

If the above two chunks didn't result in output, we're good!

```{r}
#Check that dropped values weren't ambiguous
tds2_wave1_long_recoded_nodupes %>% 
  filter(dropped) %>%
  group_by(SID, item) %>%
  summarize(noinfo = all(length(unlist(old.value)) < 1)) %>%
  ungroup() %>%
  summarize(n_with_info = sum(!noinfo))

tds2_wave1_long_recoded_nodupes %>% 
    filter(dropped) %>%
    group_by(SID, item) %>%
    filter(!all(length(unlist(old.value)) < 1)) %>%
    mutate(old.value = paste(old.value, collaps = ' ')) %>%
    knitr::kable()
```



